{"key": "SPARK-54496", "project": "SPARK", "title": "Fix schema evolution for dataframe Merge Into API", "status": "Open", "reporter": "Szehon Ho", "created": "2025-11-25T02:32:20.000+0000", "description": "[~aokolnychyi] tested and saw that Merge Into schema evolution is broken for dataframe API.", "comments": ["I am working on a fix, should be make a pr soon"], "labels": [], "summary": "[~aokolnychyi] tested and saw that Merge Into schema evolution is broken for dat", "qna": [{"question": "What is the issue title?", "answer": "Fix schema evolution for dataframe Merge Into API"}, {"question": "Who reported this issue?", "answer": "Szehon Ho"}]}
{"key": "SPARK-54495", "project": "SPARK", "title": "Reenable test_as_spark_type_pandas_on_spark_dtype", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-25T02:15:38.000+0000", "description": "{code}\r\n======================================================================\r\nFAIL [0.004s]: test_as_spark_type_pandas_on_spark_dtype (pyspark.pandas.tests.connect.test_parity_typedef.TypeHintParityTests.test_as_spark_type_pandas_on_spark_dtype)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/pandas/tests/test_typedef.py\", line 353, in test_as_spark_type_pandas_on_spark_dtype\r\n    self.assertEqual(pandas_on_spark_type(numpy_or_python_type), (dtype, spark_type))\r\nAssertionError: Tuples differ: (dtype('O'), BinaryType()) != (<class 'numpy.character'>, BinaryType())\r\n\r\nFirst differing element 0:\r\ndtype('O')\r\n<class 'numpy.character'>\r\n\r\n- (dtype('O'), BinaryType())\r\n+ (<class 'numpy.character'>, BinaryType())\r\n\r\n----------------------------------------------------------------------\r\nRan 12 tests in 0.046s\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reenable test_as_spark_type_pandas_on_spark_dtype"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54494", "project": "SPARK", "title": "Reeanble test_memory_profiler_map_in_pandas_not_supported / test_memory_profiler_pandas_udf_iterator_not_supported ", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-25T01:14:36.000+0000", "description": "```\r\n======================================================================\r\nFAIL [0.222s]: test_memory_profiler_map_in_pandas_not_supported (pyspark.sql.tests.connect.test_parity_memory_profiler.MemoryProfilerParityTests.test_memory_profiler_map_in_pandas_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/tests/test_memory_profiler.py\", line 395, in test_memory_profiler_map_in_pandas_not_supported\r\n    self.assertEqual(0, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 0 != 1 : dict_keys([29615])\r\n\r\n======================================================================\r\nFAIL [0.593s]: test_memory_profiler_pandas_udf_iterator_not_supported (pyspark.sql.tests.connect.test_parity_memory_profiler.MemoryProfilerParityTests.test_memory_profiler_pandas_udf_iterator_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/tests/test_memory_profiler.py\", line 370, in test_memory_profiler_pandas_udf_iterator_not_supported\r\n    self.assertEqual(1, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 1 != 3 : dict_keys([29647, 29648, 29650])\r\n\r\n======================================================================\r\nFAIL [0.217s]: test_memory_profiler_map_in_pandas_not_supported (pyspark.sql.tests.connect.test_parity_memory_profiler.MemoryProfilerWithoutPlanCacheParityTests.test_memory_profiler_map_in_pandas_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/tests/test_memory_profiler.py\", line 395, in test_memory_profiler_map_in_pandas_not_supported\r\n    self.assertEqual(0, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 0 != 1 : dict_keys([30115])\r\n\r\n======================================================================\r\nFAIL [0.622s]: test_memory_profiler_pandas_udf_iterator_not_supported (pyspark.sql.tests.connect.test_parity_memory_profiler.MemoryProfilerWithoutPlanCacheParityTests.test_memory_profiler_pandas_udf_iterator_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/tests/test_memory_profiler.py\", line 370, in test_memory_profiler_pandas_udf_iterator_not_supported\r\n    self.assertEqual(1, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 1 != 3 : dict_keys([30147, 30148, 30150])\r\n\r\n----------------------------------------------------------------------\r\nRan 33 tests in 13.199s\r\n\r\nFAILED (failures=4)\r\n```", "comments": [], "labels": [], "summary": "```\r\n======================================================================\r\nFAI", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_memory_profiler_map_in_pandas_not_supported / test_memory_profiler_pandas_udf_iterator_not_supported "}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54493", "project": "SPARK", "title": "PySpark's assertSchemaEqual doesn't compare MapType key and value types when ignoreNullable=True", "status": "Open", "reporter": "Josh Rosen", "created": "2025-11-24T23:55:41.000+0000", "description": "Similar to SPARK-51062, the {{pyspark.testing.assertSchemaEqual}} function doesn't properly handle {{{}MapType{}}}:\r\n\r\nFor arrays, decimals, and structs, the [existing code|https://github.com/apache/spark/blame/d14209c6ffba991b1d8ca9580708dea1ee37920e/python/pyspark/testing/utils.py#L590-L603] compares the types' parameters (e.g. element type, precision, scale, etc); this needs to be extended to also handle MapType key and value types.\r\n\r\nThe following should fail with an assertion but currently (incorrectly) passes:\r\n{code:python}\r\nfrom pyspark.sql.types import StructType, StructField, MapType, StringType, IntegerType\r\nfrom pyspark.testing import assertSchemaEqual\r\n\r\n# Note swapped key and value types:\r\ns1 = StructType([StructField(\"m\", MapType(StringType(), IntegerType()), True)])\r\ns2 = StructType([StructField(\"m\", MapType(IntegerType(), StringType()), True)])\r\n\r\n# Should raise, does not:\r\nassertSchemaEqual(s1, s2, ignoreNullable=True)\r\n{code}\r\n\u00a0", "comments": [], "labels": [], "summary": "Similar to SPARK-51062, the {{pyspark", "qna": [{"question": "What is the issue title?", "answer": "PySpark's assertSchemaEqual doesn't compare MapType key and value types when ignoreNullable=True"}, {"question": "Who reported this issue?", "answer": "Josh Rosen"}]}
{"key": "SPARK-54492", "project": "SPARK", "title": "Add sqlState to frequent errors", "status": "Open", "reporter": "Aleksandr Chernousov", "created": "2025-11-24T16:38:45.000+0000", "description": "There are some frequent errors\r\n\r\n_LEGACY_ERROR_TEMP_1201\r\n\r\n_LEGACY_ERROR_TEMP_1133", "comments": [], "labels": ["pull-request-available"], "summary": "There are some frequent errors\r\n\r\n_LEGACY_ERROR_TEMP_1201\r\n\r\n_LEGACY_ERROR_TEMP_", "qna": [{"question": "What is the issue title?", "answer": "Add sqlState to frequent errors"}, {"question": "Who reported this issue?", "answer": "Aleksandr Chernousov"}]}
{"key": "SPARK-54491", "project": "SPARK", "title": "Insert into temp view on DSv2 table failed", "status": "Resolved", "reporter": "Manu Zhang", "created": "2025-11-24T16:30:05.000+0000", "description": "I'm testing Spark 4.1 support for Iceberg in [https://github.com/apache/iceberg/pull/14155]. It looks [https://github.com/apache/spark/pull/52876] has broken this Iceberg test [https://github.com/apache/iceberg/blob/main/spark/v4.0/spark/src/test/java/org/apache/iceberg/spark/source/TestDataSourceOptions.java#L459] with following error.\r\n{code:java}\r\nException in thread \"test-extra-commit-message-writer-thread\" java.lang.RuntimeException: org.apache.spark.SparkException: [INTERNAL_ERROR] Found the unresolved operator: 'InsertIntoStatement TableReference[id#5, data#6] default_iceberg.`/var/folders/pv/9kgp4f8j685fqb28n83cdb800000gq/T/junit-16494569145098127962`.`iceberg-table`, false, false, false SQLSTATE: XX000\r\n== SQL (line 1, position 1) ==\r\nINSERT INTO target VALUES (3, 'c'), (4, 'd')\r\n^^^^^^^^^^^^^^^^^^\r\n{code}", "comments": ["Issue resolved by pull request 53196\n[https://github.com/apache/spark/pull/53196]"], "labels": ["pull-request-available"], "summary": "I'm testing Spark 4", "qna": [{"question": "What is the issue title?", "answer": "Insert into temp view on DSv2 table failed"}, {"question": "Who reported this issue?", "answer": "Manu Zhang"}]}
{"key": "SPARK-54490", "project": "SPARK", "title": "Classify \"withConnection\" exceptions in JDBCUtils", "status": "Open", "reporter": "Aleksandr Chernousov", "created": "2025-11-24T14:24:36.000+0000", "description": "Currently connection error in JDBCUtils.scala gets thrown as is - https://github.com/apache/spark/blob/d14209c6ffba991b1d8ca9580708dea1ee37920e/sql/core/src/main/scala/org/apache/spark/sql/execution/datasources/jdbc/JdbcUtils.scala#L1318\r\n\r\nNeed to classify it to catch properly (to be able to add sqlState later)", "comments": [], "labels": ["pull-request-available"], "summary": "Currently connection error in JDBCUtils", "qna": [{"question": "What is the issue title?", "answer": "Classify \"withConnection\" exceptions in JDBCUtils"}, {"question": "Who reported this issue?", "answer": "Aleksandr Chernousov"}]}
{"key": "SPARK-54489", "project": "SPARK", "title": "Avoid returning corrupted Kryo objects", "status": "Open", "reporter": "dzcxzl", "created": "2025-11-24T12:13:53.000+0000", "description": "\u00a0\r\n{code:java}\r\njava.lang.NegativeArraySizeException: -2147483645\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.resize(IdentityObjectIntMap.java:542)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:306)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:300)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:162)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.putStash(IdentityObjectIntMap.java:307)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.push(IdentityObjectIntMap.java:300)\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.put(IdentityObjectIntMap.java:162)\r\n        at com.esotericsoftware.kryo.util.MapReferenceResolver.addWrittenObject(MapReferenceResolver.java:41)\r\n        at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:681)\r\n        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:646)\r\n        at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:361)\r\n        at com.esotericsoftware.kryo.serializers.DefaultArraySerializers$ObjectArraySerializer.write(DefaultArraySerializers.java:302)\r\n        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:651)\r\n        at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:269)\r\n        at org.apache.spark.broadcast.TorrentBroadcast$.$anonfun$blockifyObject$4(TorrentBroadcast.scala:358)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1510)\r\n        at org.apache.spark.broadcast.TorrentBroadcast$.blockifyObject(TorrentBroadcast.scala:360) {code}\r\n{code:java}\r\njava.lang.ArrayIndexOutOfBoundsException: Index 688291177 out of bounds for length 3\r\n        at com.esotericsoftware.kryo.util.IdentityObjectIntMap.get(IdentityObjectIntMap.java:322)\r\n        at com.esotericsoftware.kryo.util.MapReferenceResolver.getWrittenId(MapReferenceResolver.java:46)\r\n        at com.esotericsoftware.kryo.Kryo.writeReferenceOrNull(Kryo.java:671)\r\n        at com.esotericsoftware.kryo.Kryo.writeClassAndObject(Kryo.java:646)\r\n        at org.apache.spark.serializer.KryoSerializationStream.writeObject(KryoSerializer.scala:269)\r\n        at org.apache.spark.broadcast.TorrentBroadcast$.$anonfun$blockifyObject$4(TorrentBroadcast.scala:358)\r\n        at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1510)\r\n        at org.apache.spark.broadcast.TorrentBroadcast$.blockifyObject(TorrentBroadcast.scala:360) {code}", "comments": [], "labels": ["pull-request-available"], "summary": "\u00a0\r\n{code:java}\r\njava", "qna": [{"question": "What is the issue title?", "answer": "Avoid returning corrupted Kryo objects"}, {"question": "Who reported this issue?", "answer": "dzcxzl"}]}
{"key": "SPARK-54488", "project": "SPARK", "title": "Connect JVM client leaks protobuf-java-util in shading rules", "status": "Resolved", "reporter": "Cheng Pan", "created": "2025-11-24T09:12:36.000+0000", "description": null, "comments": ["Issue resolved by pull request 53191\n[https://github.com/apache/spark/pull/53191]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Connect JVM client leaks protobuf-java-util in shading rules"}, {"question": "Who reported this issue?", "answer": "Cheng Pan"}]}
{"key": "SPARK-54487", "project": "SPARK", "title": "First MicroBatchExecution never released", "status": "Open", "reporter": "Frens Jan Rumph", "created": "2025-11-24T08:09:51.000+0000", "description": "{{MicroBatchExecution#runActivatedStream}} seems to retain a reference to the first {{MicroBatchExecutionContext}} in the {{execCtx}} variable, causing shuffles of the first micro batch to be retained forever.\r\n\r\nThe 'stream execution thread for XYZ' thread drives the trigger execution by setting the first context to be executed and then calling {{triggerExecutor.execute(...)}}. This causes {{execCtx}} to be a GC root for that first batch which prevents {{ContextCleaner}} to cleanup shuffle dependencies as this is driven by JVM garbage collection.\r\n\r\nI have a heap dump available wherein after hours of streaming, two {{CleanShuffle}} objects are retained for shuffles 0 and 1. I can provide more details based on this dump if need be.", "comments": [], "labels": [], "summary": "{{MicroBatchExecution#runActivatedStream}} seems to retain a reference to the fi", "qna": [{"question": "What is the issue title?", "answer": "First MicroBatchExecution never released"}, {"question": "Who reported this issue?", "answer": "Frens Jan Rumph"}]}
{"key": "SPARK-54486", "project": "SPARK", "title": "Reeanble test_to_feather", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:51:22.000+0000", "description": "```\r\n======================================================================\r\nERROR [0.090s]: test_to_feather (pyspark.pandas.tests.connect.io.test_parity_feather.FeatherParityTests.test_to_feather)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/pandas/tests/io/test_feather.py\", line 43, in test_to_feather\r\n    self.psdf.to_feather(path2)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/pandas/frame.py\", line 2682, in to_feather\r\n    return validate_arguments_and_invoke_function(\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/pandas/utils.py\", line 591, in validate_arguments_and_invoke_function\r\n    return pandas_func(**args)\r\n           ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/core/frame.py\", line 2938, in to_feather\r\n    to_feather(self, path, **kwargs)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/io/feather_format.py\", line 66, in to_feather\r\n    feather.write_feather(df, handles.handle, **kwargs)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pyarrow/feather.py\", line 156, in write_feather\r\n    table = Table.from_pandas(df, preserve_index=preserve_index)\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"pyarrow/table.pxi\", line 4795, in pyarrow.lib.Table.from_pandas\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 663, in dataframe_to_arrays\r\n    pandas_metadata = construct_metadata(\r\n                      ^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pyarrow/pandas_compat.py\", line 281, in construct_metadata\r\n    b'pandas': json.dumps({\r\n               ^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/json/__init__.py\", line 231, in dumps\r\n    return _default_encoder.encode(obj)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/json/encoder.py\", line 200, in encode\r\n    chunks = self.iterencode(o, _one_shot=True)\r\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/json/encoder.py\", line 258, in iterencode\r\n    return _iterencode(o, 0)\r\n           ^^^^^^^^^^^^^^^^^\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/json/encoder.py\", line 180, in default\r\n    raise TypeError(f'Object of type {o.__class__.__name__} '\r\nTypeError: Object of type PlanMetrics is not JSON serializable\r\n\r\n----------------------------------------------------------------------\r\n```", "comments": [], "labels": [], "summary": "```\r\n======================================================================\r\nERR", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_to_feather"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54485", "project": "SPARK", "title": "Reeanble test_perf_profiler_map_in_pandas_not_supported", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:38:59.000+0000", "description": "{code}\r\n======================================================================\r\nFAIL [0.217s]: test_perf_profiler_map_in_pandas_not_supported (pyspark.sql.tests.connect.test_parity_udf_profiler.UDFProfilerParityTests.test_perf_profiler_map_in_pandas_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/test_udf_profiler.py\", line 359, in test_perf_profiler_map_in_pandas_not_supported\r\n    self.assertEqual(0, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 0 != 1 : dict_keys([41611])\r\n\r\n======================================================================\r\nFAIL [0.629s]: test_perf_profiler_pandas_udf_iterator_not_supported (pyspark.sql.tests.connect.test_parity_udf_profiler.UDFProfilerParityTests.test_perf_profiler_pandas_udf_iterator_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/test_udf_profiler.py\", line 331, in test_perf_profiler_pandas_udf_iterator_not_supported\r\n    self.assertEqual(1, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 1 != 3 : dict_keys([41643, 41644, 41646])\r\n\r\n======================================================================\r\nFAIL [0.220s]: test_perf_profiler_map_in_pandas_not_supported (pyspark.sql.tests.connect.test_parity_udf_profiler.UDFProfilerWithoutPlanCacheParityTests.test_perf_profiler_map_in_pandas_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/test_udf_profiler.py\", line 359, in test_perf_profiler_map_in_pandas_not_supported\r\n    self.assertEqual(0, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 0 != 1 : dict_keys([42096])\r\n\r\n======================================================================\r\nFAIL [0.588s]: test_perf_profiler_pandas_udf_iterator_not_supported (pyspark.sql.tests.connect.test_parity_udf_profiler.UDFProfilerWithoutPlanCacheParityTests.test_perf_profiler_pandas_udf_iterator_not_supported)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/test_udf_profiler.py\", line 331, in test_perf_profiler_pandas_udf_iterator_not_supported\r\n    self.assertEqual(1, len(self.profile_results), str(self.profile_results.keys()))\r\nAssertionError: 1 != 3 : dict_keys([42128, 42129, 42131])\r\n\r\n----------------------------------------------------------------------\r\nRan 33 tests in 11.941s\r\n\r\nFAILED (failures=4)\r\n\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_perf_profiler_map_in_pandas_not_supported"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54484", "project": "SPARK", "title": "Reeanble test_simple_stream_reader and test_stream_reader", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:38:12.000+0000", "description": "{code}\r\n======================================================================\r\nERROR [10.661s]: test_simple_stream_reader (pyspark.sql.tests.connect.test_parity_python_streaming_datasource.PythonStreamingDataSourceParityTests.test_simple_stream_reader)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/test_python_streaming_datasource.py\", line 246, in test_simple_stream_reader\r\n    q = df.writeStream.foreachBatch(check_batch).start()\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n----------------------------------------------------------------------\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_simple_stream_reader and test_stream_reader"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54483", "project": "SPARK", "title": "Reeanble test_dataframes_with_incompatible_types", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:37:38.000+0000", "description": "{code}\r\n======================================================================\r\nFAIL [0.000s]: test_dataframes_with_incompatible_types (pyspark.sql.tests.connect.pandas.test_parity_pandas_map.MapInPandasParityTests.test_dataframes_with_incompatible_types) (convert='string to double', convertToArrowArraySafely=True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_map.py\", line 275, in check_dataframes_with_incompatible_types\r\n    with self.assertRaisesRegex(PythonException, expected + \"\\n\"):\r\nAssertionError: PythonException not raised\r\n\r\n======================================================================\r\nFAIL [1.040s]: test_dataframes_with_incompatible_types (pyspark.sql.tests.connect.pandas.test_parity_pandas_map.MapInPandasParityTests.test_dataframes_with_incompatible_types) (convert='string to double', convertToArrowArraySafely=False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_map.py\", line 275, in check_dataframes_with_incompatible_types\r\n    with self.assertRaisesRegex(PythonException, expected + \"\\n\"):\r\nAssertionError: PythonException not raised\r\n\r\n----------------------------------------------------------------------\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_dataframes_with_incompatible_types"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54482", "project": "SPARK", "title": "Reeanble test_apply_in_pandas_returning_column_names_*", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:35:11.000+0000", "description": "{code}\r\n======================================================================\r\nERROR [0.770s]: test_apply_in_pandas_returning_column_names (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map.GroupedApplyInPandasTests.test_apply_in_pandas_returning_column_names)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\", line 303, in test_apply_in_pandas_returning_column_names\r\n    self._test_apply_in_pandas(GroupedApplyInPandasTestsMixin.stats_with_column_names)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\", line 839, in _test_apply_in_pandas\r\n    df.groupby(\"id\").applyInPandas(f, schema=output_schema).sort(\"id\", \"mean\").toPandas()\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/dataframe.py\", line 1807, in toPandas\r\n    pdf, ei = self._session.client.to_pandas(query, self._plan.observations)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 948, in to_pandas\r\n    table, schema, metrics, observed_metrics, _ = self._execute_and_fetch(\r\n                                                  ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.PythonException: \r\n  An exception was thrown from the Python worker. Please see the stack trace below.\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 3375, in main\r\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\r\n                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2982, in read_udfs\r\n    arg_offsets, f = read_single_udf(\r\n                     ^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1306, in read_single_udf\r\n    f, return_type = read_command(pickleSer, infile)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker_util.py\", line 64, in read_command\r\n    command = serializer._read_with_length(file)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\r\n    return self.loads(obj)\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 461, in loads\r\n    return cloudpickle.loads(obj, encoding=encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: Can't get attribute 'GroupedApplyInPandasTestsMixin.stats_with_column_names' on <module 'pyspark.sql.tests.pandas.test_pandas_grouped_map' from '/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/sql/tests/pandas/test_pandas_grouped_map.py'>\r\n\r\n\r\n======================================================================\r\nERROR [0.766s]: test_apply_in_pandas_returning_column_names_sometimes (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map.GroupedApplyInPandasTests.test_apply_in_pandas_returning_column_names_sometimes)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map.py\", line 315, in test_apply_in_pandas_returning_column_names_sometimes\r\n    pdf, ei = self._session.client.to_pandas(query, self._plan.observations)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 948, in to_pandas\r\n    table, schema, metrics, observed_metrics, _ = self._execute_and_fetch(\r\n                                                  ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.PythonException: \r\n  An exception was thrown from the Python worker. Please see the stack trace below.\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 3375, in main\r\n    func, profiler, deserializer, serializer = read_udfs(pickleSer, infile, eval_type)\r\n                                               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 2982, in read_udfs\r\n    arg_offsets, f = read_single_udf(\r\n                     ^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker.py\", line 1306, in read_single_udf\r\n    f, return_type = read_command(pickleSer, infile)\r\n                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/worker_util.py\", line 64, in read_command\r\n    command = serializer._read_with_length(file)\r\n              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 173, in _read_with_length\r\n    return self.loads(obj)\r\n           ^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/serializers.py\", line 461, in loads\r\n    return cloudpickle.loads(obj, encoding=encoding)\r\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\nAttributeError: Can't get attribute 'GroupedApplyInPandasTestsMixin.stats_with_no_column_names' on <module 'pyspark.sql.tests.pandas.test_pandas_grouped_map' from '/home/runner/work/spark/spark/python/lib/pyspark.zip/pyspark/sq\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reeanble test_apply_in_pandas_returning_column_names_*"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54481", "project": "SPARK", "title": "Reenable test_apply_in_pandas_returning_incompatible_type", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:34:13.000+0000", "description": "{code}\r\n======================================================================\r\nFAIL [0.000s]: test_apply_in_pandas_returning_incompatible_type (pyspark.sql.tests.connect.pandas.test_parity_pandas_cogrouped_map.CogroupedApplyInPandasTests.test_apply_in_pandas_returning_incompatible_type) [without key] (convert='string to double', convertToArrowArraySafely=True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 574, in _test_merge_error\r\n    self.__test_merge_error(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 606, in __test_merge_error\r\n    self.__test_merge(left, right, by, fn, output_schema)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 557, in __test_merge\r\n    assert_frame_equal(expected, result)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 1218, in assert_frame_equal\r\n    raise_assert_detail(\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 614, in raise_assert_detail\r\n    raise AssertionError(msg)\r\nAssertionError: DataFrame are different\r\nDataFrame shape mismatch\r\n[left]:  (100, 4)\r\n[right]: (10, 2)\r\n======================================================================\r\nFAIL [0.000s]: test_apply_in_pandas_returning_incompatible_type (pyspark.sql.tests.connect.pandas.test_parity_pandas_cogrouped_map.CogroupedApplyInPandasTests.test_apply_in_pandas_returning_incompatible_type) [with key] (convert='string to double', convertToArrowArraySafely=True)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 584, in _test_merge_error\r\n    self.__test_merge_error(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 606, in __test_merge_error\r\n    self.__test_merge(left, right, by, fn, output_schema)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 557, in __test_merge\r\n    assert_frame_equal(expected, result)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 1218, in assert_frame_equal\r\n    raise_assert_detail(\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 614, in raise_assert_detail\r\n    raise AssertionError(msg)\r\nAssertionError: DataFrame are different\r\nDataFrame shape mismatch\r\n[left]:  (100, 4)\r\n[right]: (10, 2)\r\n======================================================================\r\nFAIL [0.000s]: test_apply_in_pandas_returning_incompatible_type (pyspark.sql.tests.connect.pandas.test_parity_pandas_cogrouped_map.CogroupedApplyInPandasTests.test_apply_in_pandas_returning_incompatible_type) [without key] (convert='string to double', convertToArrowArraySafely=False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 574, in _test_merge_error\r\n    self.__test_merge_error(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 606, in __test_merge_error\r\n    self.__test_merge(left, right, by, fn, output_schema)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 557, in __test_merge\r\n    assert_frame_equal(expected, result)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 1218, in assert_frame_equal\r\n    raise_assert_detail(\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 614, in raise_assert_detail\r\n    raise AssertionError(msg)\r\nAssertionError: DataFrame are different\r\nDataFrame shape mismatch\r\n[left]:  (100, 4)\r\n[right]: (10, 2)\r\n======================================================================\r\nFAIL [3.160s]: test_apply_in_pandas_returning_incompatible_type (pyspark.sql.tests.connect.pandas.test_parity_pandas_cogrouped_map.CogroupedApplyInPandasTests.test_apply_in_pandas_returning_incompatible_type) [with key] (convert='string to double', convertToArrowArraySafely=False)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 584, in _test_merge_error\r\n    self.__test_merge_error(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 606, in __test_merge_error\r\n    self.__test_merge(left, right, by, fn, output_schema)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_cogrouped_map.py\", line 557, in __test_merge\r\n    assert_frame_equal(expected, result)\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 1218, in assert_frame_equal\r\n    raise_assert_detail(\r\n  File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/site-packages/pandas/_testing/asserters.py\", line 614, in raise_assert_detail\r\n    raise AssertionError(msg)\r\nAssertionError: DataFrame are different\r\nDataFrame shape mismatch\r\n[left]:  (100, 4)\r\n[right]: (10, 2)\r\n----------------------------------------------------------------------\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reenable test_apply_in_pandas_returning_incompatible_type"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54480", "project": "SPARK", "title": "Reenable test_accessing_spark_session_*", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:33:30.000+0000", "description": "{code}\r\n======================================================================\r\nERROR [10.037s]: test_accessing_spark_session (pyspark.sql.tests.connect.streaming.test_parity_foreach_batch.StreamingForeachBatchParityTests.test_accessing_spark_session)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\", line 117, in test_accessing_spark_session\r\n    q = df.writeStream.foreachBatch(func).start()\r\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nDuring handling of the above exception, another exception occurred:\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\", line 121, in test_accessing_spark_session\r\n    if q:\r\n       ^\r\nUnboundLocalError: cannot access local variable 'q' where it is not associated with a value\r\n======================================================================\r\nERROR [10.027s]: test_accessing_spark_session_through_df (pyspark.sql.tests.connect.streaming.test_parity_foreach_batch.StreamingForeachBatchParityTests.test_accessing_spark_session_through_df)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/connect/streaming/test_parity_foreach_batch.py\", line 132, in test_accessing_spark_session_through_df\r\n    q = df.writeStream.foreachBatch(func).start()\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n----------------------------------------------------------------------\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reenable test_accessing_spark_session_*"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54479", "project": "SPARK", "title": "Reenable test_apply_in_pandas_with_state_basic_*", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:32:28.000+0000", "description": "{code}\r\n======================================================================\r\nERROR [10.122s]: test_apply_in_pandas_with_state_basic (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 117, in test_apply_in_pandas_with_state_basic\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n======================================================================\r\nERROR [10.032s]: test_apply_in_pandas_with_state_basic_fewer_data (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic_fewer_data)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 176, in test_apply_in_pandas_with_state_basic_fewer_data\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n======================================================================\r\nERROR [10.032s]: test_apply_in_pandas_with_state_basic_more_data (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic_more_data)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 164, in test_apply_in_pandas_with_state_basic_more_data\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n======================================================================\r\nERROR [10.035s]: test_apply_in_pandas_with_state_basic_no_state (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic_no_state)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 132, in test_apply_in_pandas_with_state_basic_no_state\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n======================================================================\r\nERROR [10.032s]: test_apply_in_pandas_with_state_basic_no_state_no_data (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic_no_state_no_data)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 143, in test_apply_in_pandas_with_state_basic_no_state_no_data\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n======================================================================\r\nERROR [10.030s]: test_apply_in_pandas_with_state_basic_with_null (pyspark.sql.tests.connect.pandas.test_parity_pandas_grouped_map_with_state.GroupedApplyInPandasWithStateTests.test_apply_in_pandas_with_state_basic_with_null)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 193, in test_apply_in_pandas_with_state_basic_with_null\r\n    self._test_apply_in_pandas_with_state_basic(func, check_results)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/tests/pandas/test_pandas_grouped_map_with_state.py\", line 91, in _test_apply_in_pandas_with_state_basic\r\n    .start()\r\n     ^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n    return self._start_internal(\r\n           ^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n    (_, properties, _) = self._session.client.execute_command(cmd)\r\n                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n    data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                     ^^^^^^^^^^^^^^^^^^^^^^^^\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n    for response in self._execute_and_fetch_as_iterator(\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n    self._handle_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n    self._handle_rpc_error(error)\r\n  File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n    raise convert_exception(\r\npyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n\r\nJVM stacktrace:\r\norg.apache.spark.SparkException\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\nCaused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n\tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n\tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n\tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n\tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n\tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n\tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n\tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n\tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n\tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n\tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n\r\n----------------------------------------------------------------------\r\nRan 9 tests in 77.762s\r\n\r\nFAILED (errors=6)\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\n======================================================================\r\n", "qna": [{"question": "What is the issue title?", "answer": "Reenable test_apply_in_pandas_with_state_basic_*"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54478", "project": "SPARK", "title": "Reeanble pyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:31:37.000+0000", "description": "{code}\r\npyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch\r\nFailed example:\r\n    q = df.writeStream.foreachBatch(func).start()\r\nException raised:\r\n    Traceback (most recent call last):\r\n      File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/doctest.py\", line 1355, in __run\r\n        exec(compile(example.source, filename, \"single\",\r\n      File \"<doctest pyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch[4]>\", line 1, in <module>\r\n        q = df.writeStream.foreachBatch(func).start()\r\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 656, in start\r\n        return self._start_internal(\r\n               ^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 625, in _start_internal\r\n        (_, properties, _) = self._session.client.execute_command(cmd)\r\n                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1148, in execute_command\r\n        data, _, metrics, observed_metrics, properties = self._execute_and_fetch(\r\n                                                         ^^^^^^^^^^^^^^^^^^^^^^^^\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1560, in _execute_and_fetch\r\n        for response in self._execute_and_fetch_as_iterator(\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1537, in _execute_and_fetch_as_iterator\r\n        self._handle_error(error)\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1811, in _handle_error\r\n        self._handle_rpc_error(error)\r\n      File \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/client/core.py\", line 1882, in _handle_rpc_error\r\n        raise convert_exception(\r\n    pyspark.errors.exceptions.connect.SparkException: Python worker failed to connect back.\r\n    JVM stacktrace:\r\n    org.apache.spark.SparkException\r\n    \tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:281)\r\n    \tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n    \tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n    \tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n    \tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n    \tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n    \tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n    \tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n    Caused by: java.net.SocketTimeoutException: Timed out while waiting for the Python worker to connect back\r\n    \tat org.apache.spark.api.python.PythonWorkerFactory.createSimpleWorker(PythonWorkerFactory.scala:263)\r\n    \tat org.apache.spark.api.python.StreamingPythonRunner.init(StreamingPythonRunner.scala:79)\r\n    \tat org.apache.spark.sql.connect.planner.StreamingForeachBatchHelper$.pythonForeachBatchWrapper(StreamingForeachBatchHelper.scala:154)\r\n    \tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.handleWriteStreamOperationStart(SparkConnectPlanner.scala:3497)\r\n    \tat org.apache.spark.sql.connect.planner.SparkConnectPlanner.process(SparkConnectPlanner.scala:2844)\r\n    \tat org.apache.spark.sql.connect.execution.SparkConnectPlanExecution.handlePlan(SparkConnectPlanExecution.scala:95)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1(ExecuteThreadRunner.scala:225)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.$anonfun$executeInternal$1$adapted(ExecuteThreadRunner.scala:197)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$2(SessionHolder.scala:396)\r\n    \tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:804)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.$anonfun$withSession$1(SessionHolder.scala:396)\r\n    \tat org.apache.spark.JobArtifactSet$.withActiveJobArtifactState(JobArtifactSet.scala:94)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.$anonfun$withResources$1(ArtifactManager.scala:112)\r\n    \tat org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:185)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.withClassLoaderIfNeeded(ArtifactManager.scala:102)\r\n    \tat org.apache.spark.sql.artifact.ArtifactManager.withResources(ArtifactManager.scala:111)\r\n    \tat org.apache.spark.sql.connect.service.SessionHolder.withSession(SessionHolder.scala:395)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.executeInternal(ExecuteThreadRunner.scala:197)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner.org$apache$spark$sql$connect$execution$ExecuteThreadRunner$$execute(ExecuteThreadRunner.scala:126)\r\n    \tat org.apache.spark.sql.connect.execution.ExecuteThreadRunner$ExecutionThread.run(ExecuteThreadRunner.scala:334)\r\n**********************************************************************\r\nFile \"/home/runner/work/spark/spark-4.0/python/pyspark/sql/connect/streaming/readwriter.py\", line 626, in pyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch\r\nFailed example:\r\n    q.stop()\r\nException raised:\r\n    Traceback (most recent call last):\r\n      File \"/opt/hostedtoolcache/Python/3.11.14/x64/lib/python3.11/doctest.py\", line 1355, in __run\r\n        exec(compile(example.source, filename, \"single\",\r\n      File \"<doctest pyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch[6]>\", line 1, in <module>\r\n        q.stop()\r\n        ^\r\n    NameError: name 'q' is not defined\r\n**********************************************************************\r\n{code}", "comments": [], "labels": [], "summary": "{code}\r\npyspark", "qna": [{"question": "What is the issue title?", "answer": "Reeanble pyspark.sql.connect.streaming.readwriter.DataStreamWriter.foreachBatch"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54477", "project": "SPARK", "title": "Fix broken tests in Spark Connect 4.0 client <> master server", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-24T07:30:24.000+0000", "description": "There are many tests broken Spark Connect 4.0 client <> master server. We should fix them all.\r\n\r\nInvestigated in https://github.com/apache/spark/pull/53188", "comments": [], "labels": [], "summary": "There are many tests broken Spark Connect 4", "qna": [{"question": "What is the issue title?", "answer": "Fix broken tests in Spark Connect 4.0 client <> master server"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54476", "project": "SPARK", "title": "Add try_mod func to improve test coverage on test_functions.py", "status": "Open", "reporter": "Jie-Kai(Jay) Chang", "created": "2025-11-24T04:25:06.000+0000", "description": "I noticed try_mod in python/pyspark/sql/functions/builtin.py haven't been tested yet.\r\nSo I open this issue to fix it.", "comments": ["I am new to this, so if this is not necessary please let me know."], "labels": [], "summary": "I noticed try_mod in python/pyspark/sql/functions/builtin", "qna": [{"question": "What is the issue title?", "answer": "Add try_mod func to improve test coverage on test_functions.py"}, {"question": "Who reported this issue?", "answer": "Jie-Kai(Jay) Chang"}]}
{"key": "SPARK-54475", "project": "SPARK", "title": "Add master-server, branch-4.0-client, Python 3.11", "status": "Open", "reporter": "Hyukjin Kwon", "created": "2025-11-23T21:43:22.000+0000", "description": "Add 4.0 version of https://github.com/apache/spark/commit/50b7d56eb2c2bbabd12b17bdf15337b875422fc4 instead.", "comments": [], "labels": ["pull-request-available"], "summary": "Add 4", "qna": [{"question": "What is the issue title?", "answer": "Add master-server, branch-4.0-client, Python 3.11"}, {"question": "Who reported this issue?", "answer": "Hyukjin Kwon"}]}
{"key": "SPARK-54474", "project": "SPARK", "title": "Disable the XML reports on tests that are supposed to fail", "status": "Resolved", "reporter": "Tian Gao", "created": "2025-11-23T21:36:45.000+0000", "description": "We added two tests that are supposed to fail:\r\n * pyspark.testing.tests.test_fail\r\n * pyspark.testing.tests.test_fail_in_set_up_class\r\n\r\nWhen running as a test module, they are fine because we are actually testing the return code. However, they wrote xml reports just like other tests. Our current testing infra is broken so we did not realize, but they reported that the tests failed. After we fix the testing infra it would be confused by the reports. We should not keep these reports.", "comments": ["Issue resolved by pull request 53187\n[https://github.com/apache/spark/pull/53187]"], "labels": ["pull-request-available"], "summary": "We added two tests that are supposed to fail:\r\n * pyspark", "qna": [{"question": "What is the issue title?", "answer": "Disable the XML reports on tests that are supposed to fail"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54473", "project": "SPARK", "title": "Add AVRO read and write support for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-23T18:35:30.000+0000", "description": "Add AVRO read and write support for Spark's TIME type.\r\n\r\nReading AVRO files containing TIME columns\r\nWriting TIME columns to AVRO format\r\nUsing to_avro() and from_avro() functions with TIME columns", "comments": ["Issue resolved by pull request 53189\n[https://github.com/apache/spark/pull/53189]"], "labels": ["pull-request-available"], "summary": "Add AVRO read and write support for Spark's TIME type", "qna": [{"question": "What is the issue title?", "answer": "Add AVRO read and write support for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54472", "project": "SPARK", "title": "Add ORC read and write support for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-23T17:39:30.000+0000", "description": "Add ORC read and write\u00a0support for Spark's TIME type.\r\n\r\nReading ORC files containing TIME columns\r\nWriting TIME columns to ORC format", "comments": ["Issue resolved by pull request 53185\n[https://github.com/apache/spark/pull/53185]"], "labels": ["pull-request-available"], "summary": "Add ORC read and write\u00a0support for Spark's TIME type", "qna": [{"question": "What is the issue title?", "answer": "Add ORC read and write support for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54471", "project": "SPARK", "title": "Remove `build_python_3.11_macos.yml` CI", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-23T16:17:42.000+0000", "description": null, "comments": ["Issue resolved by pull request 53184\n[https://github.com/apache/spark/pull/53184]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Remove `build_python_3.11_macos.yml` CI"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54470", "project": "SPARK", "title": "Fix `BlockManagerDecommissionIntegrationSuite` to wait shuffle migrations", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-23T15:33:30.000+0000", "description": "- https://github.com/apache/spark/actions/runs/19608517338/job/56150848584\r\n\r\n{code}\r\n- SPARK-46957: Migrated shuffle files should be able to cleanup from executor *** FAILED ***\r\n  0 was not greater than or equal to 12 (BlockManagerDecommissionIntegrationSuite.scala:422)\r\n{code}", "comments": ["Issue resolved by pull request 53183\n[https://github.com/apache/spark/pull/53183]"], "labels": ["pull-request-available"], "summary": "- https://github", "qna": [{"question": "What is the issue title?", "answer": "Fix `BlockManagerDecommissionIntegrationSuite` to wait shuffle migrations"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54469", "project": "SPARK", "title": "Fix `StreamingContextSuite.stop slow receiver gracefully` test to clean up `SprakContext`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-23T15:15:54.000+0000", "description": "- https://github.com/apache/spark/actions/runs/19608517338/job/56150848587\r\n{code}\r\n- SPARK-22955 graceful shutdown shouldn't lead to job generation error *** FAILED ***\r\n  The code passed to failAfter did not complete within 20 minutes. (StreamingContextSuite.scala:861)\r\n{code}", "comments": ["Issue resolved by pull request 53182\n[https://github.com/apache/spark/pull/53182]"], "labels": ["pull-request-available"], "summary": "- https://github", "qna": [{"question": "What is the issue title?", "answer": "Fix `StreamingContextSuite.stop slow receiver gracefully` test to clean up `SprakContext`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54468", "project": "SPARK", "title": "[SDP] SparkException: [INTERNAL_ERROR] Cannot find main error class 'MATERIALIZED_VIEW_WITH_MULTIPLE_QUERIES'", "status": "Open", "reporter": "Jacek Laskowski", "created": "2025-11-23T12:59:05.000+0000", "description": "It looks like {{MATERIALIZED_VIEW_WITH_MULTIPLE_QUERIES}} and {{PIPELINE_GRAPH_NOT_TOPOLOGICALLY_SORTED}} error classes are used (referenced) in SDP, but never defined.\r\n{noformat}\r\norg.apache.spark.SparkException: [INTERNAL_ERROR] Cannot find main error class 'MATERIALIZED_VIEW_WITH_MULTIPLE_QUERIES' SQLSTATE: XX000\r\n\tat org.apache.spark.SparkException$.internalError(SparkException.scala:92)\r\n\tat org.apache.spark.SparkException$.internalError(SparkException.scala:96)\r\n\tat org.apache.spark.ErrorClassesJsonReader.$anonfun$getMessageTemplate$1(ErrorClassesJSONReader.scala:113)\r\n\tat scala.collection.immutable.BitmapIndexedMapNode.getOrElse(HashMap.scala:717)\r\n\tat scala.collection.immutable.HashMap.getOrElse(HashMap.scala:720)\r\n\tat org.apache.spark.ErrorClassesJsonReader.getMessageTemplate(ErrorClassesJSONReader.scala:113)\r\n\tat org.apache.spark.ErrorClassesJsonReader.getErrorMessage(ErrorClassesJSONReader.scala:43)\r\n\tat org.apache.spark.SparkThrowableHelper$.getMessage(SparkThrowableHelper.scala:61)\r\n\tat org.apache.spark.SparkThrowableHelper$.getMessage(SparkThrowableHelper.scala:48)\r\n\tat org.apache.spark.sql.AnalysisException.<init>(AnalysisException.scala:59)\r\n\tat org.apache.spark.sql.AnalysisException.<init>(AnalysisException.scala:116)\r\n\tat org.apache.spark.sql.pipelines.graph.GraphValidations.$anonfun$validateMultiQueryTables$4(GraphValidations.scala:50)\r\n{noformat}", "comments": [], "labels": ["pull-request-available"], "summary": "It looks like {{MATERIALIZED_VIEW_WITH_MULTIPLE_QUERIES}} and {{PIPELINE_GRAPH_N", "qna": [{"question": "What is the issue title?", "answer": "[SDP] SparkException: [INTERNAL_ERROR] Cannot find main error class 'MATERIALIZED_VIEW_WITH_MULTIPLE_QUERIES'"}, {"question": "Who reported this issue?", "answer": "Jacek Laskowski"}]}
{"key": "SPARK-54467", "project": "SPARK", "title": "Disable `actions/cache` on MacOS CIs", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-23T07:22:28.000+0000", "description": "- https://github.com/orgs/community/discussions/180160\r\n- https://github.com/actions/runner-images/issues/13341", "comments": ["Issue resolved by pull request 53180\n[https://github.com/apache/spark/pull/53180]"], "labels": ["pull-request-available"], "summary": "- https://github", "qna": [{"question": "What is the issue title?", "answer": "Disable `actions/cache` on MacOS CIs"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54466", "project": "SPARK", "title": "Re-enable `actions/cache` on MacOS", "status": "Open", "reporter": "Dongjoon Hyun", "created": "2025-11-23T07:20:25.000+0000", "description": "https://github.com/orgs/community/discussions/180160\r\nhttps://github.com/actions/runner-images/issues/13341", "comments": [], "labels": [], "summary": "https://github", "qna": [{"question": "What is the issue title?", "answer": "Re-enable `actions/cache` on MacOS"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54465", "project": "SPARK", "title": "Remove `build_python_connect35.yml` GitHub Action job", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-23T04:00:54.000+0000", "description": null, "comments": ["Issue resolved by pull request 53178\n[https://github.com/apache/spark/pull/53178]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Remove `build_python_connect35.yml` GitHub Action job"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54464", "project": "SPARK", "title": "Remove duplicate output.reserve calls in assembleVariantBatch", "status": "Resolved", "reporter": "Xinyu Zou", "created": "2025-11-23T01:52:04.000+0000", "description": null, "comments": ["Issue resolved by pull request 53170\n[https://github.com/apache/spark/pull/53170]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Remove duplicate output.reserve calls in assembleVariantBatch"}, {"question": "Who reported this issue?", "answer": "Xinyu Zou"}]}
{"key": "SPARK-54463", "project": "SPARK", "title": "Add CSV serialization and deserialization support for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-23T00:06:28.000+0000", "description": "Add CSV serialization and deserialization support for Spark's TIME type.\r\n\r\nReading CSV files containing TIME columns\r\nWriting TIME columns to CSV format\r\nUsing from_csv() and to_csv() functions with TIME type", "comments": ["Issue resolved by pull request 53175\n[https://github.com/apache/spark/pull/53175]"], "labels": ["pull-request-available"], "summary": "Add CSV serialization and deserialization support for Spark's TIME type", "qna": [{"question": "What is the issue title?", "answer": "Add CSV serialization and deserialization support for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54462", "project": "SPARK", "title": "Delta DataFrameWriter saveAsTable with Overwrite mode broken in connect mode", "status": "Open", "reporter": "Juliusz Sompolski", "created": "2025-11-22T17:59:17.000+0000", "description": "Spark's SaveMode.Overwrite is documented as:\r\n\r\n```\r\n\u00a0 \u00a0 \u00a0 \u00a0 * if data/table already exists, existing data is expected to be overwritten\r\n\u00a0 \u00a0 \u00a0 \u00a0 * by the contents of the DataFrame.\r\n\r\n```\r\nIt does not define the behaviour of overwriting the table metadata (schema, etc). Delta datasource interpretation of this API documentation of DataFrameWriter V1 is to not replace table schema, unless Delta-specific option \"overwriteSchema\" is set\u00a0to true.\r\n\r\nHowever, DataFrameWriter V1 creates a ReplaceTableAsSelect plan, which is the same as\u00a0the plan of DataFrameWriterV2 createOrReplace API, which is documented as:\r\n\r\n```\r\n\u00a0 \u00a0 \u00a0 \u00a0* The output table's schema, partition layout, properties, and other configuration\r\n\u00a0 \u00a0 \u00a0 \u00a0* will be based on the contents of the data frame and the configuration set on this\r\n\u00a0 \u00a0 \u00a0 \u00a0* writer. If the table exists, its configuration and data will be replaced.\r\n```\r\n\r\nTherefore, for calls via DataFrameWriter V2 createOrReplace, the metadata always needs\u00a0to be replaced, and Delta datasource doesn't use the overwriteSchema option.\r\nSince the created plan is exactly the same, Delta had used a very ugly hack to detect where the API call is coming from based on the stack trace of the call.\r\n\r\nIn Spark 4.1 in connect mode, this stopped working because planning and execution of the commands go decoupled, and the stack trace no longer contains this point where the plan got created.\r\n\r\nTo retain compatibility of the Delta datasource with Spark 4.1 in connect mode, Spark provides this explicit storage option to indicate to Delta datasource that this call is coming from DataFrameWriter V1.\r\n\r\nFollowup: Since the details of the documented semantics of Spark's DataFrameWriter V1\u00a0 saveAsTable API differs from that of CREATE/REPLACE TABLE AS SELECT, Spark should\u00a0 not be reusing the exact same logical plan for these APIs.\r\nExisting Datasources which have been implemented following Spark's documentation of\u00a0these APIs should have a way to differentiate between these APIs.\r\n\r\nHowever, at this point releasing Spark 4.1 as is would cause data corruption issues with Delta in DataFrameWriter saveAsTable in overwrite mode, as it would not be correctly interpreting it's overwriteSchema mode.", "comments": [], "labels": ["pull-request-available"], "summary": "Spark's SaveMode", "qna": [{"question": "What is the issue title?", "answer": "Delta DataFrameWriter saveAsTable with Overwrite mode broken in connect mode"}, {"question": "Who reported this issue?", "answer": "Juliusz Sompolski"}]}
{"key": "SPARK-54461", "project": "SPARK", "title": "Add XML serialization and deserialization support for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-22T17:43:09.000+0000", "description": "Add XML serialization and deserialization support for Spark's TIME type.\r\n\r\nReading XML files containing TIME columns\r\nWriting TIME columns to XML format\r\nUsing from_xml() and to_xml() functions with TIME type", "comments": ["Issue resolved by pull request 53174\n[https://github.com/apache/spark/pull/53174]"], "labels": ["pull-request-available"], "summary": "Add XML serialization and deserialization support for Spark's TIME type", "qna": [{"question": "What is the issue title?", "answer": "Add XML serialization and deserialization support for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54460", "project": "SPARK", "title": "Mark `StateStoreInstanceMetricSuite` as `ExtendedSQLTest`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-22T06:00:46.000+0000", "description": null, "comments": ["Issue resolved by pull request 53169\n[https://github.com/apache/spark/pull/53169]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Mark `StateStoreInstanceMetricSuite` as `ExtendedSQLTest`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54459", "project": "SPARK", "title": "Increase  `StateStoreSuite.maintenance` test timeout to 2 minutes", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-22T03:33:41.000+0000", "description": null, "comments": ["Issue resolved by pull request 53168\n[https://github.com/apache/spark/pull/53168]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Increase  `StateStoreSuite.maintenance` test timeout to 2 minutes"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54458", "project": "SPARK", "title": "test_report is barely working on github", "status": "Resolved", "reporter": "Tian Gao", "created": "2025-11-22T03:13:15.000+0000", "description": "The github action `test_report` is barely working. It almost fails instantly. We should fix it.", "comments": ["Issue resolved by pull request 53167\n[https://github.com/apache/spark/pull/53167]"], "labels": ["pull-request-available"], "summary": "The github action `test_report` is barely working", "qna": [{"question": "What is the issue title?", "answer": "test_report is barely working on github"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54457", "project": "SPARK", "title": "Move tests from ApplyInPandasTests into ApplyInPandasTestsMixin", "status": "Resolved", "reporter": "Yicong Huang", "created": "2025-11-22T01:07:57.000+0000", "description": "We should move tests in [test_pandas_grouped_map.py|https://github.com/databricks-eng/runtime/pull/177430/files/c993c059f20fc8460063840ef500c386c6395dc1#diff-5450bd7ba5e660f71e81d2086376ce5ee84449c64fd350038dd9e3920dd11e65]\u00a0 under {{ApplyInPandasTestsMixin}}\u00a0instead of\u00a0{{ApplyInPandasTests.}}", "comments": ["I will fix it.", "This is a false alarm. The tests are already there in the `ApplyInPandasTestsMixin`. Please close this ticket."], "labels": [], "summary": "We should move tests in [test_pandas_grouped_map", "qna": [{"question": "What is the issue title?", "answer": "Move tests from ApplyInPandasTests into ApplyInPandasTestsMixin"}, {"question": "Who reported this issue?", "answer": "Yicong Huang"}]}
{"key": "SPARK-54456", "project": "SPARK", "title": "Avoid fork after import dangerous libraries", "status": "Resolved", "reporter": "Tian Gao", "created": "2025-11-21T23:58:27.000+0000", "description": "It's impossible to guarantee the safety of a fork after multiple threads are used.\r\n\r\n[https://discuss.python.org/t/switching-default-multiprocessing-context-to-spawn-on-posix-as-well/21868]\r\n\r\nThat's why Python issues a warning in such cases after 3.12. However, our daemon is not designed to be safe. It could import an arbitrary library before fork and potentially cause a deadlock after fork.", "comments": ["Issue resolved by pull request 53166\n[https://github.com/apache/spark/pull/53166]"], "labels": ["pull-request-available"], "summary": "It's impossible to guarantee the safety of a fork after multiple threads are use", "qna": [{"question": "What is the issue title?", "answer": "Avoid fork after import dangerous libraries"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54455", "project": "SPARK", "title": "Disable a flaky `unmanaged memory tracking with off-heap memory enabled` test in MacOS CI", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-21T23:28:31.000+0000", "description": null, "comments": ["Issue resolved by pull request 53165\n[https://github.com/apache/spark/pull/53165]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Disable a flaky `unmanaged memory tracking with off-heap memory enabled` test in MacOS CI"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54454", "project": "SPARK", "title": "Enable variant logical type and shredding configs by default", "status": "Open", "reporter": "Harsh Motwani", "created": "2025-11-21T23:09:41.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Enable variant logical type and shredding configs by default"}, {"question": "Who reported this issue?", "answer": "Harsh Motwani"}]}
{"key": "SPARK-54453", "project": "SPARK", "title": "Improve test coverage on pyspark", "status": "Open", "reporter": "Tian Gao", "created": "2025-11-21T22:07:10.000+0000", "description": "This is an umbrella JIRA for the effort to improve our pyspark coverage.\r\n\r\nWith some recent fixes on our infra, we can finally get relatively accurate coverage data for our test suite. We are now at 89%, with about 7000 lines not fully covered. I think we have some low-hanging fruit and I plan to improve this number when I don't know what to do.", "comments": ["HI, may I help with this?", "HI, may I help with this?"], "labels": [], "summary": "This is an umbrella JIRA for the effort to improve our pyspark coverage", "qna": [{"question": "What is the issue title?", "answer": "Improve test coverage on pyspark"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54452", "project": "SPARK", "title": "Fix empty response from SparkConnect server for spark.sql(...) inside FlowFunction", "status": "Resolved", "reporter": "Yuheng Chang", "created": "2025-11-21T20:46:49.000+0000", "description": "n PR SPARK-54020, we added support for {{spark.sql(...)}} inside a FlowFunction for SDP. For these calls, instead of eagerly executing the SQL, the Spark Connect server should return the raw logical plan to the client and defer execution to the flow function.\r\n\r\nHowever, in that PR we constructed the response object but forgot to actually return it to the Spark Connect client, so the client received an empty response.\r\n\r\nThis went unnoticed in tests because, when the client sees an empty\u00a0{{spark.sql(...)}}\u00a0response,\u00a0[it falls back to creating an empty DataFrame holding the raw logical plan|https://github.com/apache/spark/blob/master/python/pyspark/sql/connect/session.py#L829-L835], which happens to match the desired behavior. We should fixe the bug by returning the proper response instead of relying on that implicit fallback.", "comments": ["Issue resolved by pull request 53156\n[https://github.com/apache/spark/pull/53156]"], "labels": ["pull-request-available"], "summary": "n PR SPARK-54020, we added support for {{spark", "qna": [{"question": "What is the issue title?", "answer": "Fix empty response from SparkConnect server for spark.sql(...) inside FlowFunction"}, {"question": "Who reported this issue?", "answer": "Yuheng Chang"}]}
{"key": "SPARK-54451", "project": "SPARK", "title": "Add JSON serialization and deserialization support for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-21T20:30:24.000+0000", "description": "Add JSON serialization and deserialization support for Spark's TIME type.\r\n\r\n* Reading JSON files containing TIME columns\r\n* Writing TIME columns to JSON format\r\n* Using from_json() and to_json() functions with TIME type", "comments": ["Issue resolved by pull request 53160\n[https://github.com/apache/spark/pull/53160]"], "labels": ["pull-request-available"], "summary": "Add JSON serialization and deserialization support for Spark's TIME type", "qna": [{"question": "What is the issue title?", "answer": "Add JSON serialization and deserialization support for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54450", "project": "SPARK", "title": "We should be able to run test from unittest style string", "status": "Open", "reporter": "Tian Gao", "created": "2025-11-21T19:09:13.000+0000", "description": "Currently we can run individual pyspark tests by\r\n\r\nrun-tests --testname=\"test.module TestClass.test_case\"\r\n\r\nBut unittest will report errors with style of test.module.TestClass.test_case - it's something people already get used to.\r\n\r\nIt's fine that we have our own style, but it would be nice if we can support copy-paste directly from unittest report.", "comments": [], "labels": ["pull-request-available"], "summary": "Currently we can run individual pyspark tests by\r\n\r\nrun-tests --testname=\"test", "qna": [{"question": "What is the issue title?", "answer": "We should be able to run test from unittest style string"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54449", "project": "SPARK", "title": "Spark UI display unexpected \"Storage Memory\" capacity when spark.memory.offHeap.enabled is false", "status": "Open", "reporter": "Yifeng Wang", "created": "2025-11-21T13:48:28.000+0000", "description": "Dear Spark Community:\r\n\r\n*Current Behavior:* In the Spark UI (Executors tab) and Spark History Server, the \"Storage Memory\" column displays the total capacity as the sum of On-Heap Storage Memory + Off-Heap Storage Memory. Even when the configuration {{spark.memory.offHeap.enabled}} is explicitly set to {{{}false{}}}, the UI still adds the value of {{spark.memory.offHeap.size}} to the total displayed capacity.\r\n\r\n*Expected Behavior:* Perhaps when {{spark.memory.offHeap.enabled}} is set to {{{}false{}}}, the \"Storage Memory\" total in the UI should *only* reflect the On-Heap Storage Memory? The {{spark.memory.offHeap.size}} configuration should be ignored in the UI display calculation, similar to how it is ignored in YARN resource allocation logic.\r\n\r\n\u00a0\r\n\r\n*Personal Understandings:*\u00a0The issue stems from how {{BlockManager}} reports memory to the {{{}BlockManagerMaster{}}}. {{UnifiedMemoryManager}} initializes {{maxOffHeapMemory}} based on the configuration {{spark.memory.offHeap.size}} regardless of the {{enabled}} flag. Then {{BlockManager}} reads this value via {{memoryManager.maxOffHeapStorageMemory}} and passes it to the {{registerBlockManager}} RPC call. {{At register}} method, the total memory is calculated by simply adding on-heap and off-heap values without checking if off-heap is enabled.\r\nAt ther parts of the codebase, such as {{Client.scala}} (YARN) and {{{}ResourceProfile.scala{}}}, which correctly utilize {{Utils.checkOffHeapEnabled}} to ensure off-heap memory is treated as 0 when the feature is disabled.\r\n\r\n*Proposed Fix:*\u00a0 Perhaps we need enforce the {{checkOffHeapEnabled}} logic before aggregating the total memory for the UI?\r\n\r\n\u00a0\r\n\r\n---\r\n\r\n*Steps to Reproduce:*\r\n # Configure a Spark application with the following settings:\r\n\r\n * \r\n ** {{spark.memory.offHeap.enabled=false}}\r\n\r\n * \r\n ** {{spark.memory.offHeap.size=10g}} (or any non-zero value)\r\n\r\n\u00a0\r\n\r\n*Screenshots:*\r\n1. Comment out configs\r\n\r\n!image-2025-11-21-21-49-34-881.png!\r\n\r\nGot: (Storage Memory =2 GiB)\r\n\r\n!image-2025-11-21-22-04-45-581.png|width=344,height=325!\r\n\r\n\u00a0\r\n\r\n\u00a0\r\n\r\n2. Enable configs\r\n\r\n!image-2025-11-21-22-03-25-116.png|width=750,height=37!\r\n\r\nGot: (Storage Memory =12 GiB)\r\n\r\n!image-2025-11-21-22-03-34-768.png|width=377,height=422!\r\n\r\n\u00a0", "comments": [], "labels": [], "summary": "Dear Spark Community:\r\n\r\n*Current Behavior:* In the Spark UI (Executors tab) and", "qna": [{"question": "What is the issue title?", "answer": "Spark UI display unexpected \"Storage Memory\" capacity when spark.memory.offHeap.enabled is false"}, {"question": "Who reported this issue?", "answer": "Yifeng Wang"}]}
{"key": "SPARK-54448", "project": "SPARK", "title": "Fix docs and error message because CREATE TEMP VIEW does not support IF NOT EXISTS", "status": "Resolved", "reporter": "Cheng Pan", "created": "2025-11-21T07:59:49.000+0000", "description": null, "comments": ["Issue resolved by pull request 53153\n[https://github.com/apache/spark/pull/53153]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Fix docs and error message because CREATE TEMP VIEW does not support IF NOT EXISTS"}, {"question": "Who reported this issue?", "answer": "Cheng Pan"}]}
{"key": "SPARK-54447", "project": "SPARK", "title": "Upgrade icu4j to 78.1", "status": "Resolved", "reporter": "Yang Jie", "created": "2025-11-21T03:59:26.000+0000", "description": null, "comments": ["Issue resolved by pull request 53092\n[https://github.com/apache/spark/pull/53092]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Upgrade icu4j to 78.1"}, {"question": "Who reported this issue?", "answer": "Yang Jie"}]}
{"key": "SPARK-54446", "project": "SPARK", "title": "FPGrowth supports local filesystem", "status": "Open", "reporter": "Ruifeng Zheng", "created": "2025-11-21T02:47:13.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "FPGrowth supports local filesystem"}, {"question": "Who reported this issue?", "answer": "Ruifeng Zheng"}]}
{"key": "SPARK-54445", "project": "SPARK", "title": "Fix configuration related to ThresholdFilter in log4j2.properties within hive-thriftserver module", "status": "Resolved", "reporter": "Yang Jie", "created": "2025-11-21T02:32:39.000+0000", "description": null, "comments": ["Issue resolved by pull request 53139\n[https://github.com/apache/spark/pull/53139]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Fix configuration related to ThresholdFilter in log4j2.properties within hive-thriftserver module"}, {"question": "Who reported this issue?", "answer": "Yang Jie"}]}
{"key": "SPARK-54444", "project": "SPARK", "title": "Relax DSv2 table checks to restore previous behavior", "status": "Open", "reporter": "Anton Okolnychyi", "created": "2025-11-21T01:38:08.000+0000", "description": "We need to relax recently introduced DSv2 table checks on refresh to restore the original behavior that was supported by built-in tables and other DSv1 connectors like Delta.", "comments": [], "labels": [], "summary": "We need to relax recently introduced DSv2 table checks on refresh to restore the", "qna": [{"question": "What is the issue title?", "answer": "Relax DSv2 table checks to restore previous behavior"}, {"question": "Who reported this issue?", "answer": "Anton Okolnychyi"}]}
{"key": "SPARK-54443", "project": "SPARK", "title": "Repartition key extraction", "status": "Open", "reporter": "B. Micheal Okutubo", "created": "2025-11-21T00:09:32.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Repartition key extraction"}, {"question": "Who reported this issue?", "answer": "B. Micheal Okutubo"}]}
{"key": "SPARK-54442", "project": "SPARK", "title": "Add numeric conversion functions for TIME type", "status": "Resolved", "reporter": "Vinod KC", "created": "2025-11-20T22:58:23.000+0000", "description": "Add numeric conversion functions for TIME type that are available for TIMESTAMP.\u00a0\r\neg : Existing numeric conversion for TIMESTAMP :\u00a0\r\n{code:java}\r\nSELECT timestamp_seconds(1230219000);-- Output: 2008-12-25 07:30:00\r\nSELECT timestamp_seconds(1230219000.123);  -- Supports fractional-- Output: 2008-12-25 07:30:00.123\r\nSELECT timestamp_millis(1230219000123);-- Output: 2008-12-25 07:30:00.123\r\nSELECT timestamp_micros(1230219000123123);-- Output: 2008-12-25 07:30:00.123123\r\nSELECT unix_seconds(timestamp'2020-12-01 14:30:08Z');-- Output: 1606833008\r\nSELECT unix_millis(timestamp'2020-12-01 14:30:08Z');-- Output: 1606833008000\r\nSELECT unix_micros(timestamp'2020-12-01 14:30:08Z');-- Output: 1606833008000000\r\n\r\n{code}\r\n\u00a0\r\n\r\nAdd similar functions for\u00a0 *TIME* type, that will help to:\r\n # Create TIME values from numeric representations (seconds/milliseconds/microseconds since midnight)\r\n # Extract numeric values from TIME for calculations or data exchange with external systems\r\n\r\n*Proposal*\r\n\r\nAdd six new SQL functions to support numeric conversions for TIME type:\r\n * Constructor Functions (Numeric \u2192 TIME)\r\n\r\n{code:java}\r\n1) time_from_seconds(seconds) - Create TIME from seconds since midnight (supports fractional seconds via DECIMAL)\r\n2) time_from_millis(millis) - Create TIME from milliseconds since midnight  \r\n3) time_from_micros(micros) - Create TIME from microseconds since midnight {code}\r\n * Extractor Functions (TIME \u2192 Numeric)\r\n\r\n{code:java}\r\n4) time_to_seconds(time) - Extract seconds since midnight as DECIMAL(14,6) to preserve fractional seconds\r\n5) time_to_millis(time) - Extract milliseconds since midnight as BIGINT\r\n6) time_to_micros(time) - Extract microseconds since midnight as BIGINT {code}", "comments": ["Issue resolved by pull request 53147\n[https://github.com/apache/spark/pull/53147]"], "labels": ["pull-request-available"], "summary": "Add numeric conversion functions for TIME type that are available for TIMESTAMP", "qna": [{"question": "What is the issue title?", "answer": "Add numeric conversion functions for TIME type"}, {"question": "Who reported this issue?", "answer": "Vinod KC"}]}
{"key": "SPARK-54441", "project": "SPARK", "title": "Enable coverage data on workers", "status": "Resolved", "reporter": "Tian Gao", "created": "2025-11-20T21:40:40.000+0000", "description": "A big chunk of coverage data that we are missing is from workers. The workers.py itself has 1400+ missing lines, more than 2%+ of our total code. There are other functions that are executed by the worker which do not have coverage data either.\r\n\r\nWe have plenty of tests that uses those function, we just miss coverage data, because the worker process is always brutally killed. We can hook the worker process in coverage run so it dumps the data before it's too late.", "comments": ["Issue resolved by pull request 53145\n[https://github.com/apache/spark/pull/53145]"], "labels": ["pull-request-available"], "summary": "A big chunk of coverage data that we are missing is from workers", "qna": [{"question": "What is the issue title?", "answer": "Enable coverage data on workers"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54440", "project": "SPARK", "title": "Give default pipeline spec file more idiomatic name, `spark-pipeline.yml`", "status": "Resolved", "reporter": "Sanford Ryza", "created": "2025-11-20T21:20:56.000+0000", "description": "In the current implementation of Declarative Pipelines, the default name for the pipeline configuration YML file is \"pipeline.yml\". This is inconsistent with other user-provided Spark configuration file names:\r\n- spark-env.sh\r\n- spark-defaults.conf\r\n\r\nChanging it to spark-pipeline.yml would be more consistent.", "comments": ["Issue resolved by pull request 53144\n[https://github.com/apache/spark/pull/53144]"], "labels": ["pull-request-available"], "summary": "In the current implementation of Declarative Pipelines, the default name for the", "qna": [{"question": "What is the issue title?", "answer": "Give default pipeline spec file more idiomatic name, `spark-pipeline.yml`"}, {"question": "Who reported this issue?", "answer": "Sanford Ryza"}]}
{"key": "SPARK-54439", "project": "SPARK", "title": "KeyGroupedPartitioning and join key size mismatch", "status": "Resolved", "reporter": "Peter Toth", "created": "2025-11-20T19:20:50.000+0000", "description": null, "comments": ["Issue resolved by pull request 53142\n[https://github.com/apache/spark/pull/53142]"], "labels": ["correctness", "pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "KeyGroupedPartitioning and join key size mismatch"}, {"question": "Who reported this issue?", "answer": "Peter Toth"}]}
{"key": "SPARK-54438", "project": "SPARK", "title": "Consolidate serde for SQL_GROUPED_AGG_ARROW", "status": "Open", "reporter": "Yicong Huang", "created": "2025-11-20T19:06:20.000+0000", "description": "Similar to SPARK-54316, We need to merge ArrowStreamAggArrowIterUDFSerializer with ArrowStreamArrowUDFSerializer\r\n\r\n.", "comments": [], "labels": ["pull-request-available"], "summary": "Similar to SPARK-54316, We need to merge ArrowStreamAggArrowIterUDFSerializer wi", "qna": [{"question": "What is the issue title?", "answer": "Consolidate serde for SQL_GROUPED_AGG_ARROW"}, {"question": "Who reported this issue?", "answer": "Yicong Huang"}]}
{"key": "SPARK-54436", "project": "SPARK", "title": "Fix error formatting for incompatible table metadata checks", "status": "Resolved", "reporter": "Anton Okolnychyi", "created": "2025-11-20T18:51:30.000+0000", "description": "Fix error formatting for incompatible table metadata checks added by SPARK-53924 and SPARK-54157.", "comments": ["Issue resolved by pull request 53115\n[https://github.com/apache/spark/pull/53115]"], "labels": ["pull-request-available"], "summary": "Fix error formatting for incompatible table metadata checks added by SPARK-53924", "qna": [{"question": "What is the issue title?", "answer": "Fix error formatting for incompatible table metadata checks"}, {"question": "Who reported this issue?", "answer": "Anton Okolnychyi"}]}
{"key": "SPARK-54435", "project": "SPARK", "title": "spark-pipelines init should avoid overwriting existing directory", "status": "Resolved", "reporter": "Sanford Ryza", "created": "2025-11-20T15:16:44.000+0000", "description": "If the spark-pipelines init command is provided the name of an existing directory, it will overwrite it. We should instead error to avoid an accidentally destructive action.\r\n", "comments": ["Issue resolved by pull request 53140\n[https://github.com/apache/spark/pull/53140]"], "labels": ["pull-request-available"], "summary": "If the spark-pipelines init command is provided the name of an existing director", "qna": [{"question": "What is the issue title?", "answer": "spark-pipelines init should avoid overwriting existing directory"}, {"question": "Who reported this issue?", "answer": "Sanford Ryza"}]}
{"key": "SPARK-54434", "project": "SPARK", "title": "find-spark-home should not \"exit\"", "status": "Open", "reporter": "Stefaan Lippens", "created": "2025-11-20T11:32:47.000+0000", "description": "the find-spark-home utility ( https://github.com/apache/spark/blob/d1af9a305718d89b9260987f31323e809611966a/bin/find-spark-home ) is intended to be \"sourced\":\r\n\r\nbq.  ... Should be included using \"source\" directive.\r\n\r\nIt has \"short-circuit\" to skip everything if SPARK_HOME is already set:\r\n\r\n{code:bash}\r\n# Short circuit if the user already has this set.\r\nif [ ! -z \"${SPARK_HOME}\" ]; then\r\n   exit 0\r\nelif ...\r\n{code}\r\n\r\nBut this does an {{exit 0}}, which practically means that the active shell session of the user (where they are sourcing this script) is terminated.\r\nFor example, if you accidentally execute \"source find-spark-home\" twice, you lose your shell\r\n\r\n\r\ninstead of {{exit 0}}, I think it should use {{return 0}} or just do nothing (as there is nothing else after the whole if construct)\r\n", "comments": [], "labels": [], "summary": "the find-spark-home utility ( https://github", "qna": [{"question": "What is the issue title?", "answer": "find-spark-home should not \"exit\""}, {"question": "Who reported this issue?", "answer": "Stefaan Lippens"}]}
{"key": "SPARK-54433", "project": "SPARK", "title": "Remove unnecessary syncrhonized usage in standalone worker", "status": "Open", "reporter": "Tengfei Huang", "created": "2025-11-20T08:33:09.000+0000", "description": "Worker is a `ThreadSafeRpcEndpoint`, no need to use synchronized block if there are no extra async operations while handling the rpc messages.", "comments": [], "labels": [], "summary": "Worker is a `ThreadSafeRpcEndpoint`, no need to use synchronized block if there ", "qna": [{"question": "What is the issue title?", "answer": "Remove unnecessary syncrhonized usage in standalone worker"}, {"question": "Who reported this issue?", "answer": "Tengfei Huang"}]}
{"key": "SPARK-54432", "project": "SPARK", "title": "Use `4.1.0-preview4-java21-scala` image for preview examples", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-20T02:52:06.000+0000", "description": null, "comments": ["Issue resolved by pull request 419\n[https://github.com/apache/spark-kubernetes-operator/pull/419]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Use `4.1.0-preview4-java21-scala` image for preview examples"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54431", "project": "SPARK", "title": "Update `integration-test-ubuntu-spark41` to use Spark `4.1.0-preview4-java21`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-20T02:47:36.000+0000", "description": null, "comments": ["Issue resolved by pull request 264\n[https://github.com/apache/spark-connect-swift/pull/264]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Update `integration-test-ubuntu-spark41` to use Spark `4.1.0-preview4-java21`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54430", "project": "SPARK", "title": "Use `4.1.0-preview4` instead of `RC1`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-20T00:59:09.000+0000", "description": null, "comments": ["Issue resolved by pull request 263\n[https://github.com/apache/spark-connect-swift/pull/263]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Use `4.1.0-preview4` instead of `RC1`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54429", "project": "SPARK", "title": "Publish Apache Spark `4.1.0-preview4` to docker registry", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-20T00:51:10.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Publish Apache Spark `4.1.0-preview4` to docker registry"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54428", "project": "SPARK", "title": "Upgrade Spark to `4.1.0-preview4`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-20T00:48:35.000+0000", "description": null, "comments": ["Issue resolved by pull request 418\n[https://github.com/apache/spark-kubernetes-operator/pull/418]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Upgrade Spark to `4.1.0-preview4`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54427", "project": "SPARK", "title": "Fix ColumnarRow to be able to copy variants", "status": "Resolved", "reporter": "Richard Chen", "created": "2025-11-20T00:14:34.000+0000", "description": "currently, trying to copy a ColumnarRow with a variant type will error due to a missing `if` statement to cover variant types. we should fix it", "comments": ["Issue resolved by pull request 53137\n[https://github.com/apache/spark/pull/53137]"], "labels": ["pull-request-available"], "summary": "currently, trying to copy a ColumnarRow with a variant type will error due to a ", "qna": [{"question": "What is the issue title?", "answer": "Fix ColumnarRow to be able to copy variants"}, {"question": "Who reported this issue?", "answer": "Richard Chen"}]}
{"key": "SPARK-54426", "project": "SPARK", "title": "Fix `release-build.sh` to detect `REPO_ID` correctly", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-19T23:40:10.000+0000", "description": null, "comments": ["Issue resolved by pull request 53136\n[https://github.com/apache/spark/pull/53136]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Fix `release-build.sh` to detect `REPO_ID` correctly"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54425", "project": "SPARK", "title": "Show coverage on source file only", "status": "Resolved", "reporter": "Tian Gao", "created": "2025-11-19T23:03:50.000+0000", "description": "Currently we show coverage for tests - which is misleading. We don't care about the coverage of the tests, only the source code that we write. Also we could do everything in .coveragerc, instead of duplicating it in the script.", "comments": ["Issue resolved by pull request 53135\n[https://github.com/apache/spark/pull/53135]"], "labels": ["pull-request-available"], "summary": "Currently we show coverage for tests - which is misleading", "qna": [{"question": "What is the issue title?", "answer": "Show coverage on source file only"}, {"question": "Who reported this issue?", "answer": "Tian Gao"}]}
{"key": "SPARK-54424", "project": "SPARK", "title": "Failures during recaching must not fail operations", "status": "Open", "reporter": "Anton Okolnychyi", "created": "2025-11-19T22:12:50.000+0000", "description": "After recent changes in SPARK-54387, we may now mark write operations as failed even though they successfully committed to the table but the cache refresh was unsuccessful.", "comments": [], "labels": ["pull-request-available"], "summary": "After recent changes in SPARK-54387, we may now mark write operations as failed ", "qna": [{"question": "What is the issue title?", "answer": "Failures during recaching must not fail operations"}, {"question": "Who reported this issue?", "answer": "Anton Okolnychyi"}]}
{"key": "SPARK-54423", "project": "SPARK", "title": "Create the OffsetMap to enable tracking of streaming progress via name", "status": "Open", "reporter": "Eric Marnadi", "created": "2025-11-19T21:24:56.000+0000", "description": "Currently source progress is tracked by ordinal in the logical plan, which is brittle as sources change over the course of the query. This format will enable tracking source progress by name.\u00a0", "comments": [], "labels": [], "summary": "Currently source progress is tracked by ordinal in the logical plan, which is br", "qna": [{"question": "What is the issue title?", "answer": "Create the OffsetMap to enable tracking of streaming progress via name"}, {"question": "Who reported this issue?", "answer": "Eric Marnadi"}]}
{"key": "SPARK-54422", "project": "SPARK", "title": "Increase `spark.kubernetes.allocation.batch.size` to 20", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-19T20:20:41.000+0000", "description": null, "comments": ["Issue resolved by pull request 53134\n[https://github.com/apache/spark/pull/53134]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Increase `spark.kubernetes.allocation.batch.size` to 20"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54421", "project": "SPARK", "title": "LocalDataToArrowConversion fails on Windows for very low and high datetime/TimestampType values", "status": "Open", "reporter": "Martin Bode", "created": "2025-11-19T18:11:17.000+0000", "description": "When trying to create a `DataFrame` from a Python list of dicts where some values are very low (<`1970-01-01`) or high (>`3001-01-19`), this will lead to an error.\r\n\r\nThis seem to be specific for {*}Windows OS{*}.\r\nh1. Reproduce\r\n{code:python}\r\nfrom datetime import datetime\r\n\r\ndata = [\r\n    {\"id\": 1, \"some_datetime\": datetime(1970, 1, 1, 3, 4, 5)},  # \u274c causes error\r\n    {\"id\": 2, \"some_datetime\": datetime(1970, 1, 2, 3, 4, 5)},  # \u2705 works fine\r\n    {\"id\": 3, \"some_datetime\": datetime(2025, 1, 2, 3, 4, 5)},  # \u2705 works fine\r\n    {\"id\": 4, \"some_datetime\": datetime(3001, 1, 19, 3, 4, 5)},  # \u2705 works fine\r\n    {\"id\": 5, \"some_datetime\": datetime(3001, 1, 20, 3, 4, 5)},  # \u274c causes error\r\n    {\"id\": 6, \"some_datetime\": datetime(9999, 1, 2, 3, 4, 5)},  # \u274c causes error\r\n]\r\n\r\ndf_testdata = spark.createDataFrame(data=data, schema=\"id LONG, some_datetime TIMESTAMP\")\r\n\r\ndf_testdata.show(truncate=False)\r\n{code}\r\nh1. Error\r\n{code:python}\r\n---------------------------------------------------------------------------\r\nOSError                                   Traceback (most recent call last)\r\nCell In[76], line 12\r\n      1 from datetime import datetime\r\n      3 data = [\r\n      4     {\"id\": 1, \"some_datetime\": datetime(1970, 1, 1, 3, 4, 5)},  # \u274c causes error\r\n      5     {\"id\": 2, \"some_datetime\": datetime(1970, 1, 2, 3, 4, 5)},  # \u2705 works fine\r\n   (...)      9     {\"id\": 6, \"some_datetime\": datetime(9999, 1, 2, 3, 4, 5)},  # \u274c causes error\r\n     10 ]\r\n---> 12 df_testdata = spark.createDataFrame(data=data, schema=\"id LONG, some_datetime TIMESTAMP\")\r\n     14 df_testdata.show(truncate=False)\r\n\r\nFile c:\\...\\.venv\\Lib\\site-packages\\pyspark\\sql\\connect\\session.py:707, in SparkSession.createDataFrame(self, data, schema, samplingRatio, verifySchema)\r\n    700     from pyspark.sql.conversion import (\r\n    701         LocalDataToArrowConversion,\r\n    702     )\r\n    704     # Spark Connect will try its best to build the Arrow table with the\r\n    705     # inferred schema in the client side, and then rename the columns and\r\n    706     # cast the datatypes in the server side.\r\n--> 707     _table = LocalDataToArrowConversion.convert(_data, _schema, prefers_large_types)\r\n    709 # TODO: Beside the validation on number of columns, we should also check\r\n    710 # whether the Arrow Schema is compatible with the user provided Schema.\r\n    711 if _num_cols is not None and _num_cols != _table.shape[1]:\r\n\r\nFile c:\\...\\.venv\\Lib\\site-packages\\pyspark\\sql\\conversion.py:347, in LocalDataToArrowConversion.convert(data, schema, use_large_var_types)\r\n    345 if isinstance(item, dict):\r\n    346     for i, col in enumerate(column_names):\r\n--> 347         pylist[i].append(column_convs[i](item.get(col)))\r\n    348 else:\r\n    349     if len(item) != len(column_names):\r\n\r\nFile c:\\...\\.venv\\Lib\\site-packages\\pyspark\\sql\\conversion.py:222, in LocalDataToArrowConversion._create_converter.<locals>.convert_timestamp(value)\r\n    220 else:\r\n    221     assert isinstance(value, datetime.datetime)\r\n--> 222     return value.astimezone(datetime.timezone.utc)\r\n\r\nOSError: [Errno 22] Invalid argument\r\n{code}", "comments": [], "labels": [], "summary": "When trying to create a `DataFrame` from a Python list of dicts where some value", "qna": [{"question": "What is the issue title?", "answer": "LocalDataToArrowConversion fails on Windows for very low and high datetime/TimestampType values"}, {"question": "Who reported this issue?", "answer": "Martin Bode"}]}
{"key": "SPARK-54420", "project": "SPARK", "title": "Introduce State Writer for offline repartitioning", "status": "Open", "reporter": "Zifei Feng", "created": "2025-11-19T18:09:08.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Introduce State Writer for offline repartitioning"}, {"question": "Who reported this issue?", "answer": "Zifei Feng"}]}
{"key": "SPARK-54419", "project": "SPARK", "title": "Support State Reader for Multi-col-family operator", "status": "Open", "reporter": "Zifei Feng", "created": "2025-11-19T18:06:46.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Support State Reader for Multi-col-family operator"}, {"question": "Who reported this issue?", "answer": "Zifei Feng"}]}
{"key": "SPARK-54418", "project": "SPARK", "title": "Fix error messages and code formatting", "status": "Resolved", "reporter": "Jacek Laskowski", "created": "2025-11-19T17:27:43.000+0000", "description": "Fix typos and clean up code formatting in the Spark Declarative Pipelines module.", "comments": ["Issue resolved by pull request 52538\n[https://github.com/apache/spark/pull/52538]"], "labels": ["pull-request-available"], "summary": "Fix typos and clean up code formatting in the Spark Declarative Pipelines module", "qna": [{"question": "What is the issue title?", "answer": "Fix error messages and code formatting"}, {"question": "Who reported this issue?", "answer": "Jacek Laskowski"}]}
{"key": "SPARK-54417", "project": "SPARK", "title": "Fix error message for scalar subquery in IDENTIFIER clause", "status": "Resolved", "reporter": "Mihailo Timotic", "created": "2025-11-19T16:10:24.000+0000", "description": "Fix error message for scalar subquery in IDENTIFIER clause", "comments": ["Issue resolved by pull request 53133\n[https://github.com/apache/spark/pull/53133]"], "labels": ["pull-request-available"], "summary": "Fix error message for scalar subquery in IDENTIFIER clause", "qna": [{"question": "What is the issue title?", "answer": "Fix error message for scalar subquery in IDENTIFIER clause"}, {"question": "Who reported this issue?", "answer": "Mihailo Timotic"}]}
{"key": "SPARK-54416", "project": "SPARK", "title": "Remove references to Pod Security Policies from Kubernetes documentation ", "status": "Resolved", "reporter": "Jim Halfpenny", "created": "2025-11-19T10:27:57.000+0000", "description": null, "comments": ["Issue resolved by pull request 53130\n[https://github.com/apache/spark/pull/53130]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Remove references to Pod Security Policies from Kubernetes documentation "}, {"question": "Who reported this issue?", "answer": "Jim Halfpenny"}]}
{"key": "SPARK-54415", "project": "SPARK", "title": "CREATE GLOBAL TEMPORARY VIEW / TEMPORARY VIEW supports IF NOT EXISTS clause", "status": "Open", "reporter": "Cheng Pan", "created": "2025-11-19T09:43:58.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "CREATE GLOBAL TEMPORARY VIEW / TEMPORARY VIEW supports IF NOT EXISTS clause"}, {"question": "Who reported this issue?", "answer": "Cheng Pan"}]}
{"key": "SPARK-54414", "project": "SPARK", "title": "EnsureRequirements reorderJoinPredicates should use copy avoid missing tag", "status": "Resolved", "reporter": "angerszhu", "created": "2025-11-19T09:02:37.000+0000", "description": "{code:java}\r\nprivate def reorderJoinPredicates(plan: SparkPlan): SparkPlan = {\r\n  plan match {\r\n    case ShuffledHashJoinExec(\r\n      leftKeys, rightKeys, joinType, buildSide, condition, left, right, isSkew) =>\r\n      val (reorderedLeftKeys, reorderedRightKeys) =\r\n        reorderJoinKeys(leftKeys, rightKeys, left.outputPartitioning, right.outputPartitioning)\r\n      ShuffledHashJoinExec(reorderedLeftKeys, reorderedRightKeys, joinType, buildSide, condition,\r\n        left, right, isSkew)\r\n\r\n    case SortMergeJoinExec(leftKeys, rightKeys, joinType, condition, left, right, isSkew) =>\r\n      val (reorderedLeftKeys, reorderedRightKeys) =\r\n        reorderJoinKeys(leftKeys, rightKeys, left.outputPartitioning, right.outputPartitioning)\r\n      SortMergeJoinExec(reorderedLeftKeys, reorderedRightKeys, joinType, condition,\r\n        left, right, isSkew)\r\n\r\n    case other => other\r\n  }\r\n} {code}\r\nshould use copy", "comments": [], "labels": ["pull-request-available"], "summary": "{code:java}\r\nprivate def reorderJoinPredicates(plan: SparkPlan): SparkPlan = {\r\n", "qna": [{"question": "What is the issue title?", "answer": "EnsureRequirements reorderJoinPredicates should use copy avoid missing tag"}, {"question": "Who reported this issue?", "answer": "angerszhu"}]}
{"key": "SPARK-54413", "project": "SPARK", "title": "Update bootstrap to 4.6", "status": "Resolved", "reporter": "Kent Yao", "created": "2025-11-19T08:06:29.000+0000", "description": null, "comments": ["Issue resolved by pull request 53127\n[https://github.com/apache/spark/pull/53127]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Update bootstrap to 4.6"}, {"question": "Who reported this issue?", "answer": "Kent Yao"}]}
{"key": "SPARK-54412", "project": "SPARK", "title": "cleanup (drop) view created in identifier-clause.sql golden file", "status": "Resolved", "reporter": "Vlad Rozov", "created": "2025-11-18T22:29:51.000+0000", "description": "AFAIK, the convention is to clean tables/views that may cause conflict with other golden tests.", "comments": ["Issue resolved by pull request 53176\n[https://github.com/apache/spark/pull/53176]"], "labels": ["pull-request-available"], "summary": "AFAIK, the convention is to clean tables/views that may cause conflict with othe", "qna": [{"question": "What is the issue title?", "answer": "cleanup (drop) view created in identifier-clause.sql golden file"}, {"question": "Who reported this issue?", "answer": "Vlad Rozov"}]}
{"key": "SPARK-54411", "project": "SPARK", "title": "[SS] Introduce Writer for Repartition", "status": "Open", "reporter": "Zifei Feng", "created": "2025-11-18T21:31:17.000+0000", "description": "Introduce a {*}State Store Writer{*}, which will create a new state store version for each partition, that write the corresponding state rows for each partition, into the partition state store instance, under the right column family. We would create a snapshot for each state store instance and upload to the cloud.\u00a0\r\n\r\n\u00a0\r\n\r\nThe dataframe will have schema:\r\n|partition_key|key_bytes|value_bytes|column_family_name|\r\n|\u00a0|\u00a0|\u00a0|\u00a0|", "comments": [], "labels": [], "summary": "Introduce a {*}State Store Writer{*}, which will create a new state store versio", "qna": [{"question": "What is the issue title?", "answer": "[SS] Introduce Writer for Repartition"}, {"question": "Who reported this issue?", "answer": "Zifei Feng"}]}
{"key": "SPARK-54410", "project": "SPARK", "title": "Add read support for Parquet Variant logical type", "status": "Resolved", "reporter": "Harsh Motwani", "created": "2025-11-18T20:08:27.000+0000", "description": "The Variant data type has been formally adopted into the Parquet spec and versions of Parquet-Java >= 1.16.0 officially have the Variant logical type annotation. Therefore, Spark should be able to read parquet files containing the variant logical type.\r\n", "comments": ["Issue resolved by pull request 53120\n[https://github.com/apache/spark/pull/53120]"], "labels": ["pull-request-available"], "summary": "The Variant data type has been formally adopted into the Parquet spec and versio", "qna": [{"question": "What is the issue title?", "answer": "Add read support for Parquet Variant logical type"}, {"question": "Who reported this issue?", "answer": "Harsh Motwani"}]}
{"key": "SPARK-54409", "project": "SPARK", "title": "Join with other dimension tables", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:06:55.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Join with other dimension tables"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54408", "project": "SPARK", "title": "Metric view Composability", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:05:42.000+0000", "description": "metric view as source\r\n\r\ndimension refere dimensions (could be in another metric view)\r\n\r\nmeasure refers dimensions\r\n\r\nmeasure refers measures", "comments": [], "labels": [], "summary": "metric view as source\r\n\r\ndimension refere dimensions (could be in another metric", "qna": [{"question": "What is the issue title?", "answer": "Metric view Composability"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54407", "project": "SPARK", "title": "Window measures", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:04:19.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Window measures"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54406", "project": "SPARK", "title": "Support group by grouping set", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:03:48.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Support group by grouping set"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54405", "project": "SPARK", "title": "Query metric view with dimensions and measures", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:03:19.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Query metric view with dimensions and measures"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54404", "project": "SPARK", "title": "Create metric view command", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:02:47.000+0000", "description": null, "comments": [], "labels": [], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Create metric view command"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54403", "project": "SPARK", "title": "YAML parser to read metric view definition", "status": "Open", "reporter": "Linhong Liu", "created": "2025-11-18T20:02:19.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "YAML parser to read metric view definition"}, {"question": "Who reported this issue?", "answer": "Linhong Liu"}]}
{"key": "SPARK-54402", "project": "SPARK", "title": "Upgrade `gRPC Swift NIO Transport` to 2.3.0", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-18T18:21:14.000+0000", "description": null, "comments": ["Issue resolved by pull request 262\n[https://github.com/apache/spark-connect-swift/pull/262]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Upgrade `gRPC Swift NIO Transport` to 2.3.0"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54401", "project": "SPARK", "title": "Upgrade `grpc-swift-2` to 2.2.0", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-18T18:20:46.000+0000", "description": null, "comments": ["Issue resolved by pull request 261\n[https://github.com/apache/spark-connect-swift/pull/261]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Upgrade `grpc-swift-2` to 2.2.0"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54400", "project": "SPARK", "title": "Replace `HtmlUtils.parseQueryString` in `ThriftHttpServlet.java` with `HttpServletRequest.getQueryString`", "status": "Resolved", "reporter": "Kousuke Saruta", "created": "2025-11-18T18:18:38.000+0000", "description": "`HtmlUtils.parseQueryString` is\tdeprecated in Servlet 5.0 and removed in 6.0.\r\nhttps://jakarta.ee/specifications/servlet/5.0/apidocs/jakarta/servlet/http/httputils", "comments": ["Issue resolved by pull request 53119\n[https://github.com/apache/spark/pull/53119]"], "labels": ["pull-request-available"], "summary": "`HtmlUtils", "qna": [{"question": "What is the issue title?", "answer": "Replace `HtmlUtils.parseQueryString` in `ThriftHttpServlet.java` with `HttpServletRequest.getQueryString`"}, {"question": "Who reported this issue?", "answer": "Kousuke Saruta"}]}
{"key": "SPARK-54399", "project": "SPARK", "title": "Implement the st_setsrid function in Scala and PySpark", "status": "Resolved", "reporter": "Uro\u0161 Bojani\u0107", "created": "2025-11-18T17:32:25.000+0000", "description": null, "comments": ["Work in progress: https://github.com/apache/spark/pull/53117.", "Issue resolved by pull request 53117\n[https://github.com/apache/spark/pull/53117]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Implement the st_setsrid function in Scala and PySpark"}, {"question": "Who reported this issue?", "answer": "Uro\u0161 Bojani\u0107"}]}
{"key": "SPARK-54398", "project": "SPARK", "title": "Use 4.1.0-preview4 in `integration-test-(token|mac-spark41)`", "status": "Resolved", "reporter": "Dongjoon Hyun", "created": "2025-11-18T15:51:48.000+0000", "description": null, "comments": [], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Use 4.1.0-preview4 in `integration-test-(token|mac-spark41)`"}, {"question": "Who reported this issue?", "answer": "Dongjoon Hyun"}]}
{"key": "SPARK-54397", "project": "SPARK", "title": "Make `UserDefinedType` hashable", "status": "Resolved", "reporter": "Ruifeng Zheng", "created": "2025-11-18T08:36:02.000+0000", "description": null, "comments": ["Issue resolved by pull request 53113\n[https://github.com/apache/spark/pull/53113]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Make `UserDefinedType` hashable"}, {"question": "Who reported this issue?", "answer": "Ruifeng Zheng"}]}
{"key": "SPARK-54396", "project": "SPARK", "title": "Optimize Py4J calls in Dataframe.toArrow", "status": "Resolved", "reporter": "Ruifeng Zheng", "created": "2025-11-18T07:02:43.000+0000", "description": null, "comments": ["Issue resolved by pull request 53111\n[https://github.com/apache/spark/pull/53111]"], "labels": ["pull-request-available"], "summary": "", "qna": [{"question": "What is the issue title?", "answer": "Optimize Py4J calls in Dataframe.toArrow"}, {"question": "Who reported this issue?", "answer": "Ruifeng Zheng"}]}
